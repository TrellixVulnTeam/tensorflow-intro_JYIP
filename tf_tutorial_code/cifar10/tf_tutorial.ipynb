{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Tutorial @ H2T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data ready\n",
    "\n",
    "First of all, let's import some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonasrothfuss/anaconda3/envs/p3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to download the MNIST datset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Understanding the data\n",
    "The Dataset consists of three parts:\n",
    "* mnist.train (55 000 images)\n",
    "* mnist.test (10 000 images)\n",
    "* mnist.validation  (5 000 images)\n",
    "\n",
    "\n",
    "Both train and test set are split in to images (28x28) and labels (10 classes - one hot vectors):\n",
    "* mnist.train.images\n",
    "* mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of mnist.train.images: (55000, 784)\n",
      "Shape of mnist.train.labels: (55000, 10)\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnnLeIsoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efc2d70fef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Shape of mnist.train.images:\", mnist.train.images.shape)\n",
    "print(\"Shape of mnist.train.labels:\", mnist.train.labels.shape)\n",
    "\n",
    "# show a sample image\n",
    "%matplotlib inline\n",
    "image = mnist.train.images[2].reshape((28,28))\n",
    "image.shape\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "# show corresponding label (one-hot encoding)\n",
    "print(mnist.train.labels[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feeding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tensorflow_workflow.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep it simple we feed the data as numpy array via tf.placeholders:\n",
    "\n",
    "First, we need to declare a symbolic placeholder variable that hold the images that shall be inputted into the neural network and a placeholder variable for the true labels that come with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the network input x and the labels y\n",
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32, [None, 784]) #shape: (batch_size, width*height)\n",
    "y = tf.placeholder(tf.float32, [None, 10]) #shape: (batch_size, n_classes)\n",
    "\n",
    "# Define hyperparameters as placeholders\n",
    "keep_prob = tf.placeholder_with_default(0.7, ())\n",
    "learning_rate = tf.placeholder_with_default(0.001, ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define the neural network structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tensorflow_workflow2.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think about out neural network model:\n",
    "* Activations (weights $W$, biases $b$, input $x$, activations $a$)\n",
    "$$a=Wx+b$$\n",
    "* Nonlinearity\n",
    "$$sigm(a) = \\frac{1}{1+e^a}$$\n",
    "* Normalization on the top layer -> Softmax\n",
    "$$softmax(x)_i=\\frac{e^x}{\\sum_j e^x}$$\n",
    "* Loss function -> cross entropy error\n",
    "$$ L_y(\\hat{y}) = - \\sum_i y_i * log(\\hat{y}_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. layer\n",
    "layer_size_1 = 30\n",
    "W_1 = tf.get_variable(\"W_1\", shape=(784, layer_size_1), initializer=tf.initializers.random_normal)\n",
    "b_1 = tf.get_variable(\"b_1\", shape=(layer_size_1), initializer=tf.initializers.zeros)\n",
    "a_1 = tf.matmul(x,W_1)+b_1\n",
    "x_1 = tf.nn.sigmoid(a_1)\n",
    "\n",
    "#Dropout regularization\n",
    "x_1 = tf.nn.dropout(x_1, keep_prob=keep_prob)\n",
    "\n",
    "#2. layer\n",
    "layer_size_2 = 10 #n_classes\n",
    "W_2 = tf.get_variable(\"W_2\", shape=(layer_size_1, layer_size_2), initializer=tf.initializers.random_normal)\n",
    "b_2 = tf.get_variable(\"b_2\", shape=(layer_size_2), initializer=tf.initializers.zeros)\n",
    "a_2 = tf.matmul(x_1, W_2) + b_2 #logits\n",
    "y_pred = tf.nn.softmax(a_2) #shape: (batch_size, n_classes)\n",
    "\n",
    "# Cross entropy loss\n",
    "# Take the sum of y*log(y_pred) over all classes and then take the average over all instances in the batch\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_pred), reduction_indices=[1]))\n",
    "\n",
    "#However - for proper implementation use build-in tensorflow function for softmax + cross entropy \n",
    "#since this function has better numerical properties\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=a_2, labels=y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define Operations for Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tensorflow_workflow3.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have should train the network. Therefore we have to set up the optimizer operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We recommend to use the adaptive learning rate method ADAM instead of plain Stochastic Gradient Decent since it\n",
    "# usually converges way faster\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also be able to track if the training is goinig well. Therefore we define the accuracy which we can call later during the training to estimate how well the model performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decide if correctly classified (i.e. highest predicted softmax score corresponds to true label)\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_pred,1))\n",
    "# define accuracy \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Execute Network in a Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tensorflow_workflow4.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, we have just done some modelling by writing symbolic code, telling the computer how our neural network model looks like and how it should be trained. However, we have not performed a single calculation. Now it is time to actually train the network. Therefore we need to:\n",
    "1. Start a Session hold the variables and operations - it allows us to run the previously declared operations\n",
    "2. Initialize the variables (except placeholders)\n",
    "3. Perform training steps in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step 0: 6.04844 [11.74 %]\n",
      "Train step 1000: 0.954829 [75.93 %]\n",
      "Train step 2000: 0.48428 [85.30 %]\n",
      "Train step 3000: 0.606314 [88.41 %]\n",
      "Train step 4000: 0.485841 [89.91 %]\n",
      "Train step 5000: 0.402054 [91.08 %]\n",
      "Train step 6000: 0.360479 [91.69 %]\n",
      "Train step 7000: 0.443763 [92.22 %]\n",
      "Train step 8000: 0.418975 [92.75 %]\n",
      "Train step 9000: 0.289638 [93.03 %]\n",
      "Train step 10000: 0.228719 [93.22 %]\n"
     ]
    }
   ],
   "source": [
    "# Start Session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Initialize Variables (W and b Tensors)\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# Training Steps\n",
    "n_train_steps = 10001\n",
    "batch_size = 100\n",
    "\n",
    "for i in range(n_train_steps):\n",
    "    # get training batches from the train dataset\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    loss, _ = sess.run([cross_entropy, train_op], feed_dict={x: batch_x, y: batch_y, keep_prob: 0.8})\n",
    "    if i % 1000 == 0:    \n",
    "        #Run Accuracy computation on the whole test set\n",
    "        valid_acc = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0})\n",
    "        print(\"Train step %i:\"%i,loss, \"[%.2f\"%(valid_acc*100), \"%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# A CNN model with tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "# define a simle CNN network\n",
    "def CNN(x, y, is_training=True):\n",
    "    batch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                        normalizer_fn=slim.batch_norm,\n",
    "                        normalizer_params=batch_norm_params):\n",
    "        x = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "        # For slim.conv2d, default argument values are like\n",
    "        # normalizer_fn = None, normalizer_params = None, <== slim.arg_scope changes these arguments\n",
    "        # padding='SAME', activation_fn=nn.relu,\n",
    "        # weights_initializer = initializers.xavier_initializer(),\n",
    "        # biases_initializer = init_ops.zeros_initializer,\n",
    "        net = slim.conv2d(x, 32, [5, 5], scope='conv1')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "        net = slim.conv2d(net, 64, [5, 5], scope='conv2')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "        net = slim.flatten(net, scope='flatten3')\n",
    "\n",
    "        # For slim.fully_connected, default argument values are like\n",
    "        # activation_fn = nn.relu,\n",
    "        # normalizer_fn = None, normalizer_params = None, <== slim.arg_scope changes these arguments\n",
    "        # weights_initializer = initializers.xavier_initializer(),\n",
    "        # biases_initializer = init_ops.zeros_initializer,\n",
    "        net = slim.fully_connected(net, 1024, scope='fc3')\n",
    "        net = slim.dropout(net, is_training=is_training, scope='dropout3')  # 0.5 by default\n",
    "        logit = slim.fully_connected(net, 10, activation_fn=None, normalizer_fn=None, scope='fco')\n",
    "        \n",
    "        # Softmax Layer + Cross-Entropy-Loss\n",
    "        y_pred = tf.nn.softmax(logit)\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y))\n",
    "        \n",
    "        # Accuracy\n",
    "        correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_pred,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return y_pred, cross_entropy, accuracy\n",
    "\n",
    "# Define train operation (Optimizer)\n",
    "train_op = tf.train.AdamOptimizer().minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step 0: 3.27526 [0.13]\n",
      "Train step 5: 2.81625 [0.19]\n",
      "Train step 10: 3.40216 [0.05]\n",
      "Train step 15: 2.97665 [0.07]\n",
      "Train step 20: 3.18085 [0.09]\n",
      "Train step 25: 2.91839 [0.11]\n",
      "Train step 30: 3.28298 [0.09]\n",
      "Train step 35: 3.0285 [0.13]\n",
      "Train step 40: 3.25974 [0.09]\n",
      "Train step 45: 3.10605 [0.14]\n"
     ]
    }
   ],
   "source": [
    "# Start Session\n",
    "sess = tf.InteractiveSession()\n",
    "y_pred, cross_entropy, accuracy = CNN(x, y)\n",
    "\n",
    "# Initialize Variables (W and b Tensors)\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# Training Steps\n",
    "n_train_steps = 50\n",
    "batch_size = 100\n",
    "\n",
    "for i in range(n_train_steps):\n",
    "    # get training batches from the train dataset\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    loss, _, acc = sess.run([cross_entropy, train_op, accuracy], feed_dict={x: batch_x, y: batch_y})\n",
    "    if i % 5 == 0:\n",
    "        print(\"Train step %i:\"%i,loss, \"[%.2f]\"%acc)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
